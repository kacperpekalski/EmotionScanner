{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:11:28.858300Z",
     "start_time": "2025-01-09T23:11:28.853772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random"
   ],
   "id": "426d6b270e3111e6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T22:58:47.940152Z",
     "start_time": "2025-01-09T22:58:47.935995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = ['happy', 'neutral', 'sad']\n",
    "dirs = ['train', 'validation']"
   ],
   "id": "27d158610d525e17",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T22:58:48.344567Z",
     "start_time": "2025-01-09T22:58:48.302676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check how many images are in each class\n",
    "for c in classes:\n",
    "    print(f'{c}: {len(os.listdir(f\"../data/raw/{c}\"))}')"
   ],
   "id": "525ae785d8cf9a88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy: 12729\n",
      "neutral: 10225\n",
      "sad: 10011\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:05:43.095049Z",
     "start_time": "2025-01-09T23:03:02.233772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_noise_variance(image_path):\n",
    "    \"\"\"Calculate the variance of Laplacian for an image\"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    variance = laplacian.var()\n",
    "    return variance\n",
    "\n",
    "classes = ['happy', 'sad', 'neutral']\n",
    "input_dir = \"../data/raw\"\n",
    "output_dir = \"../data/preprocessed/filtered\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for c in classes:\n",
    "    os.makedirs(os.path.join(output_dir, c), exist_ok=True)\n",
    "\n",
    "for c in classes:\n",
    "    class_folder = os.path.join(input_dir, c)\n",
    "    images = os.listdir(class_folder)\n",
    "\n",
    "    filtered_images = [\n",
    "        img for img in images\n",
    "        if calculate_noise_variance(os.path.join(class_folder, img)) > 100\n",
    "    ]\n",
    "\n",
    "    for img in filtered_images:\n",
    "        image_path = os.path.join(class_folder, img)\n",
    "        output_path = os.path.join(output_dir, c, img)\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            cv2.imwrite(output_path, image)\n",
    "        else:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "\n",
    "print(\"Successfully filtered images\")"
   ],
   "id": "8bd13110cf55585e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully filtered images\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:06:43.752796Z",
     "start_time": "2025-01-09T23:06:43.716928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check how many images are in each class after filtering\n",
    "for c in classes:\n",
    "    print(f'{c}: {len(os.listdir(f\"../data/preprocessed/filtered/{c}\"))}')\n"
   ],
   "id": "3987403c5d2f077d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy: 11791\n",
      "sad: 8505\n",
      "neutral: 8943\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:18:42.334162Z",
     "start_time": "2025-01-09T23:17:25.243924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dawnsampling for each class to have the same amount of images in each class (the amount of images in the class with the smallest amount of images). Using random_state=42\n",
    "input_dir = \"../data/preprocessed/filtered\"\n",
    "output_dir = \"../data/preprocessed/downsampled\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for c in classes:\n",
    "    class_output_folder = os.path.join(output_dir, c)\n",
    "    if os.path.exists(class_output_folder):\n",
    "        for f in os.listdir(class_output_folder):\n",
    "            os.remove(os.path.join(class_output_folder, f))\n",
    "    else:\n",
    "        os.makedirs(class_output_folder)\n",
    "\n",
    "min_images = min([len(os.listdir(os.path.join(input_dir, c))) for c in classes])\n",
    "print(f\"Number of images in the smallest class: {min_images}\")\n",
    "\n",
    "for c in classes:\n",
    "    class_folder = os.path.join(input_dir, c)\n",
    "    images = os.listdir(class_folder)\n",
    "\n",
    "    downsampled_images = random.sample(images, min_images)\n",
    "\n",
    "    print(f\"Downsampling {c} class\")\n",
    "    print(f\"Original number of images: {len(images)}\")\n",
    "    print(f\"Downsampled number of images: {len(downsampled_images)}\")\n",
    "\n",
    "    for img in downsampled_images:\n",
    "        image_path = os.path.join(class_folder, img)\n",
    "        output_path = os.path.join(output_dir, c, img)\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            cv2.imwrite(output_path, image)\n",
    "        else:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "\n",
    "print(\"Downsampling completed\")"
   ],
   "id": "a509d31d7d76efd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the smallest class: 8505\n",
      "Downsampling happy class\n",
      "Original number of images: 11791\n",
      "Downsampled number of images: 8505\n",
      "Downsampling sad class\n",
      "Original number of images: 8505\n",
      "Downsampled number of images: 8505\n",
      "Downsampling neutral class\n",
      "Original number of images: 8943\n",
      "Downsampled number of images: 8505\n",
      "Downsampling completed\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:48:23.598842Z",
     "start_time": "2025-01-09T23:48:23.572687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check how many images are in each class after downsampling\n",
    "for c in classes:\n",
    "    print(f'{c}: {len(os.listdir(f\"../data/preprocessed/downsampled/{c}\"))}')"
   ],
   "id": "4c74d10192bd389b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy: 8505\n",
      "sad: 8505\n",
      "neutral: 8505\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:50:01.738311Z",
     "start_time": "2025-01-09T23:48:40.776327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resize images to 299x299\n",
    "\n",
    "target_size = (299, 299)\n",
    "input_dir = \"../data/preprocessed/downsampled\"\n",
    "output_dir = \"../data/preprocessed/resized\"\n",
    "\n",
    "for c in classes:\n",
    "    class_folder = os.path.join(input_dir, c)\n",
    "    output_class_folder = os.path.join(output_dir, c)\n",
    "    os.makedirs(output_class_folder, exist_ok=True)\n",
    "\n",
    "    images = os.listdir(class_folder)\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(class_folder, img_name)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        resized_img = cv2.resize(img, target_size)\n",
    "\n",
    "        output_path = os.path.join(output_class_folder, img_name)\n",
    "        cv2.imwrite(output_path, resized_img)\n",
    "\n",
    "print(\"Successfully resized images\")"
   ],
   "id": "6665c58c5a46a080",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully resized images\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:50:56.669101Z",
     "start_time": "2025-01-09T23:50:56.643648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check how many images are in each class after resizing\n",
    "for c in classes:\n",
    "    print(f'{c}: {len(os.listdir(f\"../data/preprocessed/resized/{c}\"))}')"
   ],
   "id": "7d382c256103a7ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy: 8505\n",
      "sad: 8505\n",
      "neutral: 8505\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:52:16.198881Z",
     "start_time": "2025-01-09T23:50:58.455508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split data into train and validation sets\n",
    "input_dir = \"../data/preprocessed/resized\"\n",
    "output_dir = \"../data/final\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for d in dirs:\n",
    "    os.makedirs(os.path.join(output_dir, d), exist_ok=True)\n",
    "    for c in classes:\n",
    "        os.makedirs(os.path.join(output_dir, d, c), exist_ok=True)\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "for c in classes:\n",
    "    class_folder = os.path.join(input_dir, c)\n",
    "    images = os.listdir(class_folder)\n",
    "\n",
    "    train_images, val_images = train_test_split(images, test_size=test_size, random_state=42)\n",
    "\n",
    "    for img, target_dir in [(train_images, 'train'), (val_images, 'validation')]:\n",
    "        for image_name in img:\n",
    "            image_path = os.path.join(class_folder, image_name)\n",
    "            output_path = os.path.join(output_dir, target_dir, c, image_name)\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                cv2.imwrite(output_path, image)\n",
    "            else:\n",
    "                print(f\"Error loading image: {image_path}\")\n",
    "\n",
    "print(\"Successfully split data into train and validation sets\")"
   ],
   "id": "ee32f75690d705b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully split data into train and validation sets\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:52:16.332482Z",
     "start_time": "2025-01-09T23:52:16.305651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check how many images are in each class after splitting\n",
    "for d in dirs:\n",
    "    for c in classes:\n",
    "        print(f'{d} {c}: {len(os.listdir(f\"../data/final/{d}/{c}\"))}')"
   ],
   "id": "9c81fc107be56c6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train happy: 6804\n",
      "train sad: 6804\n",
      "train neutral: 6804\n",
      "validation happy: 1701\n",
      "validation sad: 1701\n",
      "validation neutral: 1701\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "203632918a52a903"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
